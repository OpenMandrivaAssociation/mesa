From 53a15925da524d871b1331812cd9e91143fadc52 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Tue, 6 Oct 2020 18:54:15 -0400
Subject: [PATCH 1/7] util: remove unused util_get_L3_for_pinned_thread

Reviewed-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Acked-by: Jose Fonseca <jfonseca@vmware.com>
Part-of: <https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/7054>
---
 src/util/u_thread.h | 33 ---------------------------------
 1 file changed, 33 deletions(-)

diff --git a/src/util/u_thread.h b/src/util/u_thread.h
index af44bcfc1bd..917ffead6a5 100644
--- a/src/util/u_thread.h
+++ b/src/util/u_thread.h
@@ -117,39 +117,6 @@ util_pin_thread_to_L3(thrd_t thread, unsigned L3_index, unsigned cores_per_L3)
 #endif
 }
 
-/**
- * Return the index of L3 that the thread is pinned to. If the thread is
- * pinned to multiple L3 caches, return -1.
- *
- * \param thread        thread
- * \param cores_per_L3  number of CPU cores shared by one L3
- */
-static inline int
-util_get_L3_for_pinned_thread(thrd_t thread, unsigned cores_per_L3)
-{
-#if defined(HAVE_PTHREAD_SETAFFINITY)
-   cpu_set_t cpuset;
-
-   if (pthread_getaffinity_np(thread, sizeof(cpuset), &cpuset) == 0) {
-      int L3_index = -1;
-
-      for (unsigned i = 0; i < CPU_SETSIZE; i++) {
-         if (CPU_ISSET(i, &cpuset)) {
-            int x = i / cores_per_L3;
-
-            if (L3_index != x) {
-               if (L3_index == -1)
-                  L3_index = x;
-               else
-                  return -1; /* multiple L3s are set */
-            }
-         }
-      }
-      return L3_index;
-   }
-#endif
-   return -1;
-}
 
 /*
  * Thread statistics.
-- 
GitLab


From 96d9f7761d4b313c69664c01682aef8f13bc6c02 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Tue, 6 Oct 2020 18:59:31 -0400
Subject: [PATCH 2/7] util: consolidate thread_get_time functions

Reviewed-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Acked-by: Jose Fonseca <jfonseca@vmware.com>
Part-of: <https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/7054>
---
 src/gallium/auxiliary/hud/hud_cpu.c  |  4 ++--
 src/gallium/auxiliary/os/os_thread.h | 17 -----------------
 src/util/u_queue.c                   |  2 +-
 src/util/u_thread.h                  | 18 +++++++++++++++++-
 4 files changed, 20 insertions(+), 21 deletions(-)

diff --git a/src/gallium/auxiliary/hud/hud_cpu.c b/src/gallium/auxiliary/hud/hud_cpu.c
index f10640bb40f..767bff48841 100644
--- a/src/gallium/auxiliary/hud/hud_cpu.c
+++ b/src/gallium/auxiliary/hud/hud_cpu.c
@@ -333,7 +333,7 @@ query_api_thread_busy_status(struct hud_graph *gr, struct pipe_context *pipe)
          int64_t thread_now;
 
          if (info->main_thread) {
-            thread_now = pipe_current_thread_get_time_nano();
+            thread_now = util_current_thread_get_time_nano();
          } else {
             struct util_queue_monitoring *mon = gr->pane->hud->monitored_queue;
 
@@ -360,7 +360,7 @@ query_api_thread_busy_status(struct hud_graph *gr, struct pipe_context *pipe)
    } else {
       /* initialize */
       info->last_time = now;
-      info->last_thread_time = pipe_current_thread_get_time_nano();
+      info->last_thread_time = util_current_thread_get_time_nano();
    }
 }
 
diff --git a/src/gallium/auxiliary/os/os_thread.h b/src/gallium/auxiliary/os/os_thread.h
index f2629c5ffe5..7ca65a21dd0 100644
--- a/src/gallium/auxiliary/os/os_thread.h
+++ b/src/gallium/auxiliary/os/os_thread.h
@@ -155,21 +155,4 @@ pipe_tsd_set(pipe_tsd *tsd, void *value)
    }
 }
 
-
-
-/*
- * Thread statistics.
- */
-
-/* Return the time of the current thread's CPU time clock. */
-static inline int64_t
-pipe_current_thread_get_time_nano(void)
-{
-#if defined(HAVE_PTHREAD)
-   return u_thread_get_time_nano(pthread_self());
-#else
-   return 0;
-#endif
-}
-
 #endif /* OS_THREAD_H_ */
diff --git a/src/util/u_queue.c b/src/util/u_queue.c
index 8f6dc08b332..b1478bdf483 100644
--- a/src/util/u_queue.c
+++ b/src/util/u_queue.c
@@ -696,5 +696,5 @@ util_queue_get_thread_time_nano(struct util_queue *queue, unsigned thread_index)
    if (thread_index >= queue->num_threads)
       return 0;
 
-   return u_thread_get_time_nano(queue->threads[thread_index]);
+   return util_thread_get_time_nano(queue->threads[thread_index]);
 }
diff --git a/src/util/u_thread.h b/src/util/u_thread.h
index 917ffead6a5..d1fb95e3de1 100644
--- a/src/util/u_thread.h
+++ b/src/util/u_thread.h
@@ -124,7 +124,7 @@ util_pin_thread_to_L3(thrd_t thread, unsigned L3_index, unsigned cores_per_L3)
 
 /* Return the time of a thread's CPU time clock. */
 static inline int64_t
-u_thread_get_time_nano(thrd_t thread)
+util_thread_get_time_nano(thrd_t thread)
 {
 #if defined(HAVE_PTHREAD) && !defined(__APPLE__) && !defined(__HAIKU__)
    struct timespec ts;
@@ -138,6 +138,22 @@ u_thread_get_time_nano(thrd_t thread)
 #endif
 }
 
+/* Return the time of the current thread's CPU time clock. */
+static inline int64_t
+util_current_thread_get_time_nano(void)
+{
+#if defined(HAVE_PTHREAD)
+   return util_thread_get_time_nano(pthread_self());
+
+#elif defined(_WIN32) && !defined(__CYGWIN__)
+   /* The GetCurrentThreadId() handle is only valid within the current thread. */
+   return util_thread_get_time_nano(GetCurrentThread());
+
+#else
+   return 0;
+#endif
+}
+
 static inline bool u_thread_is_self(thrd_t thread)
 {
 #if defined(HAVE_PTHREAD)
-- 
GitLab


From 3433d193e7c1ed0ddf24deffd1ed74b5cceddf4b Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Tue, 6 Oct 2020 21:37:01 -0400
Subject: [PATCH 3/7] st/mesa: remove random L3 pinning heuristic for glthread

This is not very effective. A better solution will be added to glthread.

Reviewed-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Acked-by: Jose Fonseca <jfonseca@vmware.com>
Part-of: <https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/7054>
---
 src/gallium/auxiliary/util/u_helpers.c | 47 --------------------------
 src/gallium/auxiliary/util/u_helpers.h |  4 ---
 src/mesa/state_tracker/st_manager.c    | 11 ------
 3 files changed, 62 deletions(-)

diff --git a/src/gallium/auxiliary/util/u_helpers.c b/src/gallium/auxiliary/util/u_helpers.c
index 6fa3f1a1fcd..9856f1cf6d7 100644
--- a/src/gallium/auxiliary/util/u_helpers.c
+++ b/src/gallium/auxiliary/util/u_helpers.c
@@ -157,53 +157,6 @@ util_upload_index_buffer(struct pipe_context *pipe,
    return *out_buffer != NULL;
 }
 
-/**
- * Called by MakeCurrent. Used to notify the driver that the application
- * thread may have been changed.
- *
- * The function pins the current thread and driver threads to a group of
- * CPU cores that share the same L3 cache. This is needed for good multi-
- * threading performance on AMD Zen CPUs.
- *
- * \param upper_thread  thread in gallium frontends that also needs to be
- *                      pinned.
- */
-void
-util_pin_driver_threads_to_random_L3(struct pipe_context *ctx,
-                                     thrd_t *upper_thread)
-{
-   /* If pinning has no effect, don't do anything. */
-   if (util_cpu_caps.nr_cpus == util_cpu_caps.cores_per_L3)
-      return;
-
-   unsigned num_L3_caches = util_cpu_caps.nr_cpus /
-                            util_cpu_caps.cores_per_L3;
-
-   /* Get a semi-random number. */
-   int64_t t = os_time_get_nano();
-   unsigned cache = (t ^ (t >> 8) ^ (t >> 16)) % num_L3_caches;
-
-   /* Tell the driver to pin its threads to the selected L3 cache. */
-   if (ctx->set_context_param) {
-      ctx->set_context_param(ctx, PIPE_CONTEXT_PARAM_PIN_THREADS_TO_L3_CACHE,
-                             cache);
-   }
-
-   /* Do the same for the upper level thread if there is any (e.g. glthread) */
-   if (upper_thread)
-      util_pin_thread_to_L3(*upper_thread, cache, util_cpu_caps.cores_per_L3);
-
-   /* Optionally pin the application thread to the same L3 to get maximum
-    * performance with glthread on AMD Zen. (this function is only called
-    * with glthread) This is used to estimate and remove the overhead of
-    * Infinity Fabric between L3 caches.
-    */
-#if defined(HAVE_PTHREAD)
-   if (debug_get_bool_option("pin_app_thread", false))
-      util_pin_thread_to_L3(pthread_self(), cache, util_cpu_caps.cores_per_L3);
-#endif
-}
-
 /* This is a helper for hardware bring-up. Don't remove. */
 struct pipe_query *
 util_begin_pipestat_query(struct pipe_context *ctx)
diff --git a/src/gallium/auxiliary/util/u_helpers.h b/src/gallium/auxiliary/util/u_helpers.h
index db7b3efc711..e5748f11edf 100644
--- a/src/gallium/auxiliary/util/u_helpers.h
+++ b/src/gallium/auxiliary/util/u_helpers.h
@@ -75,10 +75,6 @@ util_varying_is_point_coord(gl_varying_slot slot, uint32_t sprite_coord_enable)
    return false;
 }
 
-void
-util_pin_driver_threads_to_random_L3(struct pipe_context *ctx,
-                                     thrd_t *upper_thread);
-
 struct pipe_query *
 util_begin_pipestat_query(struct pipe_context *ctx);
 
diff --git a/src/mesa/state_tracker/st_manager.c b/src/mesa/state_tracker/st_manager.c
index ab2bfbc1f39..d96dd68e04f 100644
--- a/src/mesa/state_tracker/st_manager.c
+++ b/src/mesa/state_tracker/st_manager.c
@@ -821,17 +821,6 @@ st_start_thread(struct st_context_iface *stctxi)
    struct st_context *st = (struct st_context *) stctxi;
 
    _mesa_glthread_init(st->ctx);
-
-   /* Pin all driver threads to one L3 cache for optimal performance
-    * on AMD Zen. This is only done if glthread is enabled.
-    *
-    * If glthread is disabled, st_draw.c re-pins driver threads regularly
-    * based on the location of the app thread.
-    */
-   struct glthread_state *glthread = &st->ctx->GLThread;
-   if (glthread->enabled && st->pipe->set_context_param) {
-      util_pin_driver_threads_to_random_L3(st->pipe, &glthread->queue.threads[0]);
-   }
 }
 
 
-- 
GitLab


From 9758b1d416a109f92e911d7bac6f00f9419affab Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Tue, 6 Oct 2020 18:44:08 -0400
Subject: [PATCH 4/7] util: add util_set_thread_affinity helpers including
 Windows support

Acked-by: Jose Fonseca <jfonseca@vmware.com>
Acked-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Part-of: <https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/7054>
---
 src/util/u_queue.c  |  10 ++---
 src/util/u_thread.h | 104 ++++++++++++++++++++++++++++++++++++++++----
 2 files changed, 99 insertions(+), 15 deletions(-)

diff --git a/src/util/u_queue.c b/src/util/u_queue.c
index b1478bdf483..b11b297a45c 100644
--- a/src/util/u_queue.c
+++ b/src/util/u_queue.c
@@ -251,19 +251,15 @@ util_queue_thread_func(void *input)
 
    free(input);
 
-#ifdef HAVE_PTHREAD_SETAFFINITY
    if (queue->flags & UTIL_QUEUE_INIT_SET_FULL_THREAD_AFFINITY) {
       /* Don't inherit the thread affinity from the parent thread.
        * Set the full mask.
        */
-      cpu_set_t cpuset;
-      CPU_ZERO(&cpuset);
-      for (unsigned i = 0; i < CPU_SETSIZE; i++)
-         CPU_SET(i, &cpuset);
+      uint32_t mask[UTIL_MAX_CPUS / 32];
 
-      pthread_setaffinity_np(pthread_self(), sizeof(cpuset), &cpuset);
+      memset(mask, 0xff, sizeof(mask));
+      util_set_current_thread_affinity(mask, NULL, UTIL_MAX_CPUS);
    }
-#endif
 
 #if defined(__linux__)
    if (queue->flags & UTIL_QUEUE_INIT_USE_MINIMUM_PRIORITY) {
diff --git a/src/util/u_thread.h b/src/util/u_thread.h
index d1fb95e3de1..3f4733592ab 100644
--- a/src/util/u_thread.h
+++ b/src/util/u_thread.h
@@ -29,9 +29,11 @@
 
 #include <stdint.h>
 #include <stdbool.h>
+#include <string.h>
 
 #include "c11/threads.h"
 #include "detect_os.h"
+#include "macros.h"
 
 #ifdef HAVE_PTHREAD
 #include <signal.h>
@@ -52,6 +54,9 @@
 #define cpu_set_t cpuset_t
 #endif
 
+/* For util_set_thread_affinity to size the mask. */
+#define UTIL_MAX_CPUS               1024  /* this should be enough */
+
 static inline thrd_t u_thread_create(int (*routine)(void *), void *param)
 {
    thrd_t thread;
@@ -94,6 +99,85 @@ static inline void u_thread_setname( const char *name )
    (void)name;
 }
 
+/**
+ * Set thread affinity.
+ *
+ * \param thread         Thread
+ * \param mask           Set this affinity mask
+ * \param old_mask       Previous affinity mask returned if not NULL
+ * \param num_mask_bits  Number of bits in both masks
+ * \return  true on success
+ */
+static inline bool
+util_set_thread_affinity(thrd_t thread,
+                         const uint32_t *mask,
+                         uint32_t *old_mask,
+                         unsigned num_mask_bits)
+{
+#if defined(HAVE_PTHREAD_SETAFFINITY)
+   cpu_set_t cpuset;
+
+   if (old_mask) {
+      if (pthread_getaffinity_np(thread, sizeof(cpuset), &cpuset) != 0)
+         return false;
+
+      memset(old_mask, 0, num_mask_bits / 32);
+      for (unsigned i = 0; i < num_mask_bits && i < CPU_SETSIZE; i++) {
+         if (CPU_ISSET(i, &cpuset))
+            old_mask[i / 32] |= 1u << (i % 32);
+      }
+   }
+
+   CPU_ZERO(&cpuset);
+   for (unsigned i = 0; i < num_mask_bits && i < CPU_SETSIZE; i++) {
+      if (mask[i / 32] & (1u << (i % 32)))
+         CPU_SET(i, &cpuset);
+   }
+   return pthread_setaffinity_np(thread, sizeof(cpuset), &cpuset) == 0;
+
+#elif defined(_WIN32) && !defined(__CYGWIN__)
+   DWORD_PTR m = mask[0];
+
+   if (sizeof(m) > 4 && num_mask_bits > 32)
+      m |= (uint64_t)mask[1] << 32;
+
+   m = SetThreadAffinityMask(thread, m);
+   if (!m)
+      return false;
+
+   if (old_mask) {
+      memset(old_mask, 0, num_mask_bits / 32);
+
+      old_mask[0] = m;
+      if (sizeof(m) > 4)
+         old_mask[1] = m >> 32;
+   }
+
+   return true;
+#else
+   return false;
+#endif
+}
+
+static inline bool
+util_set_current_thread_affinity(const uint32_t *mask,
+                                 uint32_t *old_mask,
+                                 unsigned num_mask_bits)
+{
+#if defined(HAVE_PTHREAD_SETAFFINITY)
+   return util_set_thread_affinity(pthread_self(), mask, old_mask,
+                                   num_mask_bits);
+
+#elif defined(_WIN32) && !defined(__CYGWIN__)
+   /* The GetCurrentThreadId() handle is only valid within the current thread. */
+   return util_set_thread_affinity(GetCurrentThread(), mask, old_mask,
+                                   num_mask_bits);
+
+#else
+   return false;
+#endif
+}
+
 /**
  * An AMD Zen CPU consists of multiple modules where each module has its own L3
  * cache. Inter-thread communication such as locks and atomics between modules
@@ -104,17 +188,21 @@ static inline void u_thread_setname( const char *name )
  * \param L3_index      index of the L3 cache
  * \param cores_per_L3  number of CPU cores shared by one L3
  */
-static inline void
+static inline bool
 util_pin_thread_to_L3(thrd_t thread, unsigned L3_index, unsigned cores_per_L3)
 {
-#if defined(HAVE_PTHREAD_SETAFFINITY)
-   cpu_set_t cpuset;
+   unsigned num_mask_bits = DIV_ROUND_UP((L3_index + 1) * cores_per_L3, 32);
+   uint32_t mask[UTIL_MAX_CPUS / 32];
 
-   CPU_ZERO(&cpuset);
-   for (unsigned i = 0; i < cores_per_L3; i++)
-      CPU_SET(L3_index * cores_per_L3 + i, &cpuset);
-   pthread_setaffinity_np(thread, sizeof(cpuset), &cpuset);
-#endif
+   assert((L3_index + 1) * cores_per_L3 <= UTIL_MAX_CPUS);
+
+   for (unsigned i = 0; i < cores_per_L3; i++) {
+      unsigned core = L3_index * cores_per_L3 + i;
+
+      mask[core / 32] |= 1u << (core % 32);
+   }
+
+   return util_set_thread_affinity(thread, mask, NULL, num_mask_bits);
 }
 
 
-- 
GitLab


From 4f2c2307f9e82498b2374e95aa8a17d0eb80531c Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Wed, 7 Oct 2020 07:09:01 -0400
Subject: [PATCH 5/7] util: add util_get_current_cpu using sched_getcpu and
 Windows equivalent

Acked-by: Jose Fonseca <jfonseca@vmware.com>
Acked-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Part-of: <https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/7054>
---
 src/mesa/state_tracker/st_draw.c | 12 ++----------
 src/util/u_thread.h              | 20 ++++++++++++++++++++
 2 files changed, 22 insertions(+), 10 deletions(-)

diff --git a/src/mesa/state_tracker/st_draw.c b/src/mesa/state_tracker/st_draw.c
index cbc8b139dbb..0e22d0c5a0d 100644
--- a/src/mesa/state_tracker/st_draw.c
+++ b/src/mesa/state_tracker/st_draw.c
@@ -68,13 +68,6 @@
 #include "draw/draw_context.h"
 #include "cso_cache/cso_context.h"
 
-#if defined(PIPE_OS_LINUX) && !defined(ANDROID)
-#include <sched.h>
-#define HAVE_SCHED_GETCPU 1
-#else
-#define sched_getcpu() 0
-#define HAVE_SCHED_GETCPU 0
-#endif
 
 /**
  * Set the restart index.
@@ -136,8 +129,7 @@ prepare_draw(struct st_context *st, struct gl_context *ctx)
    /* Pin threads regularly to the same Zen CCX that the main thread is
     * running on. The main thread can move between CCXs.
     */
-   if (unlikely(HAVE_SCHED_GETCPU && /* Linux */
-                /* AMD Zen */
+   if (unlikely(/* AMD Zen */
                 util_cpu_caps.nr_cpus != util_cpu_caps.cores_per_L3 &&
                 /* no glthread */
                 ctx->CurrentClientDispatch != ctx->MarshalExec &&
@@ -145,7 +137,7 @@ prepare_draw(struct st_context *st, struct gl_context *ctx)
                 pipe->set_context_param &&
                 /* do it occasionally */
                 ++st->pin_thread_counter % 512 == 0)) {
-      int cpu = sched_getcpu();
+      int cpu = util_get_current_cpu();
       if (cpu >= 0) {
          unsigned L3_cache = cpu / util_cpu_caps.cores_per_L3;
 
diff --git a/src/util/u_thread.h b/src/util/u_thread.h
index 3f4733592ab..93d8b0f92dc 100644
--- a/src/util/u_thread.h
+++ b/src/util/u_thread.h
@@ -46,6 +46,12 @@
 #include <OS.h>
 #endif
 
+#if DETECT_OS_LINUX && !defined(ANDROID)
+#include <sched.h>
+#elif defined(_WIN32) && !defined(__CYGWIN__) && _WIN32_WINNT >= 0x0600
+#include <windows.h>
+#endif
+
 #ifdef __FreeBSD__
 /* pthread_np.h -> sys/param.h -> machine/param.h
  * - defines ALIGN which clashes with our ALIGN
@@ -57,6 +63,20 @@
 /* For util_set_thread_affinity to size the mask. */
 #define UTIL_MAX_CPUS               1024  /* this should be enough */
 
+static inline int
+util_get_current_cpu(void)
+{
+#if DETECT_OS_LINUX && !defined(ANDROID)
+   return sched_getcpu();
+
+#elif defined(_WIN32) && !defined(__CYGWIN__) && _WIN32_WINNT >= 0x0600
+   return GetCurrentProcessorNumber();
+
+#else
+   return -1;
+#endif
+}
+
 static inline thrd_t u_thread_create(int (*routine)(void *), void *param)
 {
    thrd_t thread;
-- 
GitLab


From d8ea50996580a34b17059ec5456c75bb0d1f8750 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Tue, 6 Oct 2020 19:05:29 -0400
Subject: [PATCH 6/7] util: completely rewrite and do AMD Zen L3 cache pinning
 correctly

This queries the CPU cache topology correctly.

Acked-by: Jose Fonseca <jfonseca@vmware.com>
Reviewed-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Part-of: <https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/7054>
---
 .../auxiliary/util/u_threaded_context.c       |   5 +-
 src/gallium/winsys/amdgpu/drm/amdgpu_winsys.c |   5 +-
 .../winsys/radeon/drm/radeon_drm_winsys.c     |   5 +-
 src/mesa/state_tracker/st_draw.c              |   2 +-
 src/util/u_cpu_detect.c                       | 101 ++++++++++++++++--
 src/util/u_cpu_detect.h                       |  10 +-
 src/util/u_thread.h                           |  28 +----
 7 files changed, 112 insertions(+), 44 deletions(-)

diff --git a/src/gallium/auxiliary/util/u_threaded_context.c b/src/gallium/auxiliary/util/u_threaded_context.c
index f9d22c3bcb9..d8dcad57793 100644
--- a/src/gallium/auxiliary/util/u_threaded_context.c
+++ b/src/gallium/auxiliary/util/u_threaded_context.c
@@ -2002,8 +2002,9 @@ tc_set_context_param(struct pipe_context *_pipe,
 
    if (param == PIPE_CONTEXT_PARAM_PIN_THREADS_TO_L3_CACHE) {
       /* Pin the gallium thread as requested. */
-      util_pin_thread_to_L3(tc->queue.threads[0], value,
-                            util_cpu_caps.cores_per_L3);
+      util_set_thread_affinity(tc->queue.threads[0],
+                               util_cpu_caps.L3_affinity_mask[value],
+                               NULL, UTIL_MAX_CPUS);
 
       /* Execute this immediately (without enqueuing).
        * It's required to be thread-safe.
diff --git a/src/gallium/winsys/amdgpu/drm/amdgpu_winsys.c b/src/gallium/winsys/amdgpu/drm/amdgpu_winsys.c
index d554ea5a67c..8a0aedfed64 100644
--- a/src/gallium/winsys/amdgpu/drm/amdgpu_winsys.c
+++ b/src/gallium/winsys/amdgpu/drm/amdgpu_winsys.c
@@ -311,8 +311,9 @@ static void amdgpu_pin_threads_to_L3_cache(struct radeon_winsys *rws,
 {
    struct amdgpu_winsys *ws = amdgpu_winsys(rws);
 
-   util_pin_thread_to_L3(ws->cs_queue.threads[0], cache,
-                         util_cpu_caps.cores_per_L3);
+   util_set_thread_affinity(ws->cs_queue.threads[0],
+                            util_cpu_caps.L3_affinity_mask[cache],
+                            NULL, UTIL_MAX_CPUS);
 }
 
 static uint32_t kms_handle_hash(const void *key)
diff --git a/src/gallium/winsys/radeon/drm/radeon_drm_winsys.c b/src/gallium/winsys/radeon/drm/radeon_drm_winsys.c
index b9a092d9ae4..569d273a1f7 100644
--- a/src/gallium/winsys/radeon/drm/radeon_drm_winsys.c
+++ b/src/gallium/winsys/radeon/drm/radeon_drm_winsys.c
@@ -798,8 +798,9 @@ static void radeon_pin_threads_to_L3_cache(struct radeon_winsys *ws,
    struct radeon_drm_winsys *rws = (struct radeon_drm_winsys*)ws;
 
    if (util_queue_is_initialized(&rws->cs_queue)) {
-      util_pin_thread_to_L3(rws->cs_queue.threads[0], cache,
-            util_cpu_caps.cores_per_L3);
+      util_set_thread_affinity(rws->cs_queue.threads[0],
+                               util_cpu_caps.L3_affinity_mask[cache],
+                               NULL, UTIL_MAX_CPUS);
    }
 }
 
diff --git a/src/mesa/state_tracker/st_draw.c b/src/mesa/state_tracker/st_draw.c
index 0e22d0c5a0d..676db28df96 100644
--- a/src/mesa/state_tracker/st_draw.c
+++ b/src/mesa/state_tracker/st_draw.c
@@ -139,7 +139,7 @@ prepare_draw(struct st_context *st, struct gl_context *ctx)
                 ++st->pin_thread_counter % 512 == 0)) {
       int cpu = util_get_current_cpu();
       if (cpu >= 0) {
-         unsigned L3_cache = cpu / util_cpu_caps.cores_per_L3;
+         unsigned L3_cache = util_cpu_caps.cpu_to_L3[cpu];
 
          pipe->set_context_param(pipe,
                                  PIPE_CONTEXT_PARAM_PIN_THREADS_TO_L3_CACHE,
diff --git a/src/util/u_cpu_detect.c b/src/util/u_cpu_detect.c
index ab064957382..af3663a8bd6 100644
--- a/src/util/u_cpu_detect.c
+++ b/src/util/u_cpu_detect.c
@@ -37,8 +37,12 @@
 
 #include "util/u_debug.h"
 #include "u_cpu_detect.h"
+#include "u_math.h"
 #include "c11/threads.h"
 
+#include <stdio.h>
+#include <inttypes.h>
+
 #if defined(PIPE_ARCH_PPC)
 #if defined(PIPE_OS_APPLE)
 #include <sys/sysctl.h>
@@ -83,9 +87,7 @@
 #endif
 
 
-#ifdef DEBUG
 DEBUG_GET_ONCE_BOOL_OPTION(dump_cpu, "GALLIUM_DUMP_CPU", false)
-#endif
 
 
 struct util_cpu_caps util_cpu_caps;
@@ -432,21 +434,104 @@ check_os_arm_support(void)
 static void
 get_cpu_topology(void)
 {
-   /* Default. This is correct if L3 is not present or there is only one. */
+   /* Default. This is OK if L3 is not present or there is only one. */
    util_cpu_caps.cores_per_L3 = util_cpu_caps.nr_cpus;
+   util_cpu_caps.num_L3_caches = 1;
 
 #if defined(PIPE_ARCH_X86) || defined(PIPE_ARCH_X86_64)
    /* AMD Zen */
    if (util_cpu_caps.x86_cpu_type == 0x17) {
       uint32_t regs[4];
 
-      /* Query the L3 cache topology information. */
+      /* Query the L3 cache count. */
       cpuid_count(0x8000001D, 3, regs);
       unsigned cache_level = (regs[0] >> 5) & 0x7;
-      unsigned cores_per_cache = ((regs[0] >> 14) & 0xfff) + 1;
+      unsigned cores_per_L3 = ((regs[0] >> 14) & 0xfff) + 1;
+
+      if (cache_level != 3 || cores_per_L3 == util_cpu_caps.nr_cpus)
+         return;
+
+      uint32_t saved_mask[UTIL_MAX_CPUS / 32] = {0};
+      uint32_t mask[UTIL_MAX_CPUS / 32] = {0};
+      uint32_t allowed_mask[UTIL_MAX_CPUS / 32] = {0};
+      uint32_t apic_id[UTIL_MAX_CPUS];
+      bool saved = false;
+
+      /* Query APIC IDs from each CPU core.
+       *
+       * An APIC ID is a logical ID of the CPU with respect to the cache
+       * hierarchy, meaning that consecutive APIC IDs are neighbours in
+       * the hierarchy, e.g. sharing the same cache.
+       *
+       * For example, CPU 0 can have APIC ID 0 and CPU 12 can have APIC ID 1,
+       * which means that both CPU 0 and 12 are next to each other.
+       * (e.g. they are 2 threads belonging to 1 SMT2 core)
+       *
+       * We need to find out which CPUs share the same L3 cache and they can
+       * be all over the place.
+       *
+       * Querying the APIC ID can only be done by pinning the current thread
+       * to each core. The original affinity mask is saved.
+       */
+      for (unsigned i = 0; i < util_cpu_caps.nr_cpus && i < UTIL_MAX_CPUS;
+           i++) {
+         uint32_t cpu_bit = 1u << (i % 32);
+
+         mask[i / 32] = cpu_bit;
+
+         if (util_set_current_thread_affinity(mask,
+                                              !saved ? saved_mask : NULL,
+                                              UTIL_MAX_CPUS)) {
+            saved = true;
+            allowed_mask[i / 32] |= cpu_bit;
+
+            /* Query the APIC ID of the current core. */
+            cpuid(0x00000001, regs);
+            apic_id[i] = regs[1] >> 24;
+         }
+         mask[i / 32] = 0;
+      }
+
+      if (saved) {
+
+         /* We succeeded in using at least one CPU. */
+         util_cpu_caps.num_L3_caches = util_cpu_caps.nr_cpus / cores_per_L3;
+         util_cpu_caps.cores_per_L3 = cores_per_L3;
+         util_cpu_caps.L3_affinity_mask = calloc(sizeof(util_affinity_mask),
+                                                 util_cpu_caps.num_L3_caches);
 
-      if (cache_level == 3)
-         util_cpu_caps.cores_per_L3 = cores_per_cache;
+         for (unsigned i = 0; i < util_cpu_caps.nr_cpus && i < UTIL_MAX_CPUS;
+              i++) {
+            uint32_t cpu_bit = 1u << (i % 32);
+
+            if (allowed_mask[i / 32] & cpu_bit) {
+               /* Each APIC ID bit represents a topology level, so we need
+                * to round up to the next power of two.
+                */
+               unsigned L3_index = apic_id[i] /
+                                   util_next_power_of_two(cores_per_L3);
+
+               util_cpu_caps.L3_affinity_mask[L3_index][i / 32] |= cpu_bit;
+               util_cpu_caps.cpu_to_L3[i] = L3_index;
+            }
+         }
+
+         if (debug_get_option_dump_cpu()) {
+            fprintf(stderr, "CPU <-> L3 cache mapping:\n");
+            for (unsigned i = 0; i < util_cpu_caps.num_L3_caches; i++) {
+               fprintf(stderr, "  - L3 %u mask = ", i);
+               for (int j = util_cpu_caps.nr_cpus - 1; j >= 0; j -= 32)
+                  fprintf(stderr, "%08x ", util_cpu_caps.L3_affinity_mask[i][j / 32]);
+               fprintf(stderr, "\n");
+            }
+         }
+
+         /* Restore the original affinity mask. */
+         util_set_current_thread_affinity(saved_mask, NULL, UTIL_MAX_CPUS);
+      } else {
+         if (debug_get_option_dump_cpu())
+            fprintf(stderr, "Cannot set thread affinity for any thread.\n");
+      }
    }
 #endif
 }
@@ -606,7 +691,6 @@ util_cpu_detect_once(void)
 
    get_cpu_topology();
 
-#ifdef DEBUG
    if (debug_get_option_dump_cpu()) {
       debug_printf("util_cpu_caps.nr_cpus = %u\n", util_cpu_caps.nr_cpus);
 
@@ -643,7 +727,6 @@ util_cpu_detect_once(void)
       debug_printf("util_cpu_caps.has_avx512vl = %u\n", util_cpu_caps.has_avx512vl);
       debug_printf("util_cpu_caps.has_avx512vbmi = %u\n", util_cpu_caps.has_avx512vbmi);
    }
-#endif
 }
 
 static once_flag cpu_once_flag = ONCE_FLAG_INIT;
diff --git a/src/util/u_cpu_detect.h b/src/util/u_cpu_detect.h
index a09aca8fbac..2e47ee69af4 100644
--- a/src/util/u_cpu_detect.h
+++ b/src/util/u_cpu_detect.h
@@ -37,12 +37,14 @@
 
 
 #include "pipe/p_config.h"
+#include "util/u_thread.h"
 
 
 #ifdef	__cplusplus
 extern "C" {
 #endif
 
+typedef uint32_t util_affinity_mask[UTIL_MAX_CPUS / 32];
 
 struct util_cpu_caps {
    int nr_cpus;
@@ -50,7 +52,6 @@ struct util_cpu_caps {
    /* Feature flags */
    int x86_cpu_type;
    unsigned cacheline;
-   unsigned cores_per_L3;
 
    unsigned has_intel:1;
    unsigned has_tsc:1;
@@ -84,6 +85,13 @@ struct util_cpu_caps {
    unsigned has_avx512bw:1;
    unsigned has_avx512vl:1;
    unsigned has_avx512vbmi:1;
+
+   unsigned num_L3_caches;
+   unsigned cores_per_L3;
+
+   uint16_t cpu_to_L3[UTIL_MAX_CPUS];
+   /* Affinity masks for each L3 cache. */
+   util_affinity_mask *L3_affinity_mask;
 };
 
 extern struct util_cpu_caps
diff --git a/src/util/u_thread.h b/src/util/u_thread.h
index 93d8b0f92dc..bdfb05e158c 100644
--- a/src/util/u_thread.h
+++ b/src/util/u_thread.h
@@ -62,6 +62,7 @@
 
 /* For util_set_thread_affinity to size the mask. */
 #define UTIL_MAX_CPUS               1024  /* this should be enough */
+#define UTIL_MAX_L3_CACHES          UTIL_MAX_CPUS
 
 static inline int
 util_get_current_cpu(void)
@@ -198,33 +199,6 @@ util_set_current_thread_affinity(const uint32_t *mask,
 #endif
 }
 
-/**
- * An AMD Zen CPU consists of multiple modules where each module has its own L3
- * cache. Inter-thread communication such as locks and atomics between modules
- * is very expensive. It's desirable to pin a group of closely cooperating
- * threads to one group of cores sharing L3.
- *
- * \param thread        thread
- * \param L3_index      index of the L3 cache
- * \param cores_per_L3  number of CPU cores shared by one L3
- */
-static inline bool
-util_pin_thread_to_L3(thrd_t thread, unsigned L3_index, unsigned cores_per_L3)
-{
-   unsigned num_mask_bits = DIV_ROUND_UP((L3_index + 1) * cores_per_L3, 32);
-   uint32_t mask[UTIL_MAX_CPUS / 32];
-
-   assert((L3_index + 1) * cores_per_L3 <= UTIL_MAX_CPUS);
-
-   for (unsigned i = 0; i < cores_per_L3; i++) {
-      unsigned core = L3_index * cores_per_L3 + i;
-
-      mask[core / 32] |= 1u << (core % 32);
-   }
-
-   return util_set_thread_affinity(thread, mask, NULL, num_mask_bits);
-}
-
 
 /*
  * Thread statistics.
-- 
GitLab


From 5957b0c162290e444d9e57dbed07047c421e7148 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Marek=20Ol=C5=A1=C3=A1k?= <marek.olsak@amd.com>
Date: Wed, 7 Oct 2020 07:41:41 -0400
Subject: [PATCH 7/7] glthread: pin driver threads to the same L3 as the main
 thread regularly

This improves performance on my Ryzen 3900X, which has 4 L3 caches and
6 threads per L3.

The best improvement is 33% if the kernel CPU scheduler doesn't move
the main thread too often.

v2: pin only once in 128 batch flushes

Acked-by: Jose Fonseca <jfonseca@vmware.com>
Acked-by: Pierre-Eric Pelloux-Prayer <pierre-eric.pelloux-prayer@amd.com>
Part-of: <https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/7054>
---
 src/mesa/main/dd.h                  |  2 ++
 src/mesa/main/glthread.c            | 20 ++++++++++++++++++++
 src/mesa/main/glthread.h            |  3 +++
 src/mesa/state_tracker/st_context.c | 13 +++++++++++++
 4 files changed, 38 insertions(+)

diff --git a/src/mesa/main/dd.h b/src/mesa/main/dd.h
index 417f2592301..eb3c14e64a9 100644
--- a/src/mesa/main/dd.h
+++ b/src/mesa/main/dd.h
@@ -1326,6 +1326,8 @@ struct dd_function_table {
    void (*SetMaxShaderCompilerThreads)(struct gl_context *ctx, unsigned count);
    bool (*GetShaderProgramCompletionStatus)(struct gl_context *ctx,
                                             struct gl_shader_program *shprog);
+
+   void (*PinDriverToL3Cache)(struct gl_context *ctx, unsigned L3_cache);
 };
 
 
diff --git a/src/mesa/main/glthread.c b/src/mesa/main/glthread.c
index b0779435af0..eb8eb30cabc 100644
--- a/src/mesa/main/glthread.c
+++ b/src/mesa/main/glthread.c
@@ -38,6 +38,7 @@
 #include "main/hash.h"
 #include "util/u_atomic.h"
 #include "util/u_thread.h"
+#include "util/u_cpu_detect.h"
 
 
 static void
@@ -195,6 +196,25 @@ _mesa_glthread_flush_batch(struct gl_context *ctx)
    if (!next->used)
       return;
 
+   /* Pin threads regularly to the same Zen CCX that the main thread is
+    * running on. The main thread can move between CCXs.
+    */
+   if (util_cpu_caps.nr_cpus != util_cpu_caps.cores_per_L3 &&
+       /* driver support */
+       ctx->Driver.PinDriverToL3Cache &&
+       ++glthread->pin_thread_counter % 128 == 0) {
+      int cpu = util_get_current_cpu();
+
+      if (cpu >= 0) {
+         unsigned L3_cache = util_cpu_caps.cpu_to_L3[cpu];
+
+         util_set_thread_affinity(glthread->queue.threads[0],
+                                  util_cpu_caps.L3_affinity_mask[L3_cache],
+                                  NULL, UTIL_MAX_CPUS);
+         ctx->Driver.PinDriverToL3Cache(ctx, L3_cache);
+      }
+   }
+
    /* Debug: execute the batch immediately from this thread.
     *
     * Note that glthread_unmarshal_batch() changes the dispatch table so we'll
diff --git a/src/mesa/main/glthread.h b/src/mesa/main/glthread.h
index 76cb41192a8..8a98a151b3a 100644
--- a/src/mesa/main/glthread.h
+++ b/src/mesa/main/glthread.h
@@ -134,6 +134,9 @@ struct glthread_state
    /** Whether GLThread is inside a display list generation. */
    bool inside_dlist;
 
+   /** For L3 cache pinning. */
+   unsigned pin_thread_counter;
+
    /** The ring of batches in memory. */
    struct glthread_batch batches[MARSHAL_MAX_BATCHES];
 
diff --git a/src/mesa/state_tracker/st_context.c b/src/mesa/state_tracker/st_context.c
index 668a7aa7be2..1605e4682e8 100644
--- a/src/mesa/state_tracker/st_context.c
+++ b/src/mesa/state_tracker/st_context.c
@@ -908,6 +908,16 @@ st_get_driver_uuid(struct gl_context *ctx, char *uuid)
 }
 
 
+static void
+st_pin_driver_to_l3_cache(struct gl_context *ctx, unsigned L3_cache)
+{
+   struct pipe_context *pipe = st_context(ctx)->pipe;
+
+   pipe->set_context_param(pipe, PIPE_CONTEXT_PARAM_PIN_THREADS_TO_L3_CACHE,
+                           L3_cache);
+}
+
+
 static void
 st_init_driver_functions(struct pipe_screen *screen,
                          struct dd_function_table *functions)
@@ -999,6 +1009,9 @@ st_create_context(gl_api api, struct pipe_context *pipe,
    memset(&funcs, 0, sizeof(funcs));
    st_init_driver_functions(pipe->screen, &funcs);
 
+   if (pipe->set_context_param)
+      funcs.PinDriverToL3Cache = st_pin_driver_to_l3_cache;
+
    ctx = calloc(1, sizeof(struct gl_context));
    if (!ctx)
       return NULL;
-- 
GitLab

